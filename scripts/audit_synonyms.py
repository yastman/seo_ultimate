#!/usr/bin/env python3
"""
–ê—É–¥–∏—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è keywords/synonyms –≤ _clean.json —Ñ–∞–π–ª–∞—Ö.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º TZ_SEO_SYNONYMS.md
"""

import io
import json
import sys
from pathlib import Path

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")

CATEGORIES_DIR = Path(__file__).parent.parent / "categories"

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ synonyms, –∞ –Ω–µ –≤ keywords
COMMERCIAL_PATTERNS = [
    "–∫—É–ø–∏—Ç—å",
    "—Ü–µ–Ω–∞",
    "–≤ —É–∫—Ä–∞–∏–Ω–µ",
    "–≤ —É–∫—Ä–∞—ó–Ω—ñ",
    "–∫–∏–µ–≤",
    "–∫–∏—ó–≤",
    "–Ω–µ–¥–æ—Ä–æ–≥–æ",
    "–æ—Ç–∑—ã–≤—ã",
    "—Ñ–æ—Ç–æ",
    "—Å—Ç–æ–∏–º–æ—Å—Ç—å",
]

# –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (–º–æ–≥—É—Ç –±—ã—Ç—å –¥–æ–ø—É—Å—Ç–∏–º—ã –≤ keywords –µ—Å–ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
MODIFIER_PATTERNS = ["–¥–ª—è –∞–≤—Ç–æ", "–¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è", "–¥–ª—è –º–∞—à–∏–Ω—ã", "–¥–ª—è –º–∞—à–∏–Ω"]


def audit_category(json_path: Path) -> dict:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω JSON —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã."""
    issues = {
        "json_error": None,
        "no_synonyms": False,
        "commercial_in_keywords": [],
        "long_tail_in_keywords": [],  # –§—Ä–∞–∑—ã > 4 —Å–ª–æ–≤
        "keywords_count": 0,
        "synonyms_count": 0,
    }

    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        issues["json_error"] = str(e)
        return issues

    keywords = data.get("keywords", [])
    synonyms = data.get("synonyms", None)

    issues["keywords_count"] = len(keywords)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è synonyms
    if synonyms is None:
        issues["no_synonyms"] = True
    else:
        issues["synonyms_count"] = len(synonyms)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ keywords
    for kw in keywords:
        keyword_text = kw.get("keyword", "").lower()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        for pattern in COMMERCIAL_PATTERNS:
            if pattern in keyword_text:
                issues["commercial_in_keywords"].append({"keyword": kw.get("keyword"), "pattern": pattern})
                break

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ö–≤–æ—Å—Ç–æ–≤ (–±–æ–ª–µ–µ 4 —Å–ª–æ–≤)
        word_count = len(keyword_text.split())
        if word_count > 4:
            issues["long_tail_in_keywords"].append({"keyword": kw.get("keyword"), "word_count": word_count})

    return issues


def main():
    print("=" * 60)
    print("–ê–£–î–ò–¢ –†–ê–ó–î–ï–õ–ï–ù–ò–Ø KEYWORDS/SYNONYMS")
    print("=" * 60)

    all_issues = {}
    json_errors = []
    no_synonyms = []
    commercial_issues = []
    long_tail_issues = []

    for json_file in sorted(CATEGORIES_DIR.glob("*/data/*_clean.json")):
        slug = json_file.parent.parent.name
        issues = audit_category(json_file)

        if issues["json_error"]:
            json_errors.append((slug, issues["json_error"]))
            continue

        if issues["no_synonyms"]:
            no_synonyms.append(slug)

        if issues["commercial_in_keywords"]:
            for item in issues["commercial_in_keywords"]:
                commercial_issues.append((slug, item["keyword"], item["pattern"]))

        if issues["long_tail_in_keywords"]:
            for item in issues["long_tail_in_keywords"]:
                long_tail_issues.append((slug, item["keyword"], item["word_count"]))

        all_issues[slug] = issues

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüìÅ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(all_issues) + len(json_errors)}")

    if json_errors:
        print(f"\n‚ùå JSON –û–®–ò–ë–ö–ò ({len(json_errors)}):")
        for slug, error in json_errors:
            print(f"   - {slug}: {error}")

    if no_synonyms:
        print(f"\n‚ö†Ô∏è  –ö–ê–¢–ï–ì–û–†–ò–ò –ë–ï–ó SYNONYMS ({len(no_synonyms)}):")
        for slug in no_synonyms:
            print(f"   - {slug}")

    if commercial_issues:
        print(f"\nüî¥ –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ï –¢–ï–†–ú–ò–ù–´ –í KEYWORDS ({len(commercial_issues)}):")
        for slug, kw, pattern in commercial_issues:
            print(f'   - {slug}: "{kw}" (–ø–∞—Ç—Ç–µ—Ä–Ω: "{pattern}")')

    if long_tail_issues:
        print(f"\nüü° –î–õ–ò–ù–ù–´–ï –•–í–û–°–¢–´ –í KEYWORDS ({len(long_tail_issues)}):")
        for slug, kw, wc in long_tail_issues:
            print(f'   - {slug}: "{kw}" ({wc} —Å–ª–æ–≤)')

    # –ò—Ç–æ–≥
    total_problems = len(json_errors) + len(no_synonyms) + len(commercial_issues) + len(long_tail_issues)
    if total_problems == 0:
        print("\n‚úÖ –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∞–≤–∏–ª–∞–º TZ_SEO_SYNONYMS.md")
    else:
        print(f"\nüìä –ò–¢–û–ì–û –ü–†–û–ë–õ–ï–ú: {total_problems}")
        print("   - JSON –æ—à–∏–±–∫–∏:", len(json_errors))
        print("   - –ë–µ–∑ synonyms:", len(no_synonyms))
        print("   - –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –≤ keywords:", len(commercial_issues))
        print("   - –î–ª–∏–Ω–Ω—ã–µ —Ö–≤–æ—Å—Ç—ã –≤ keywords:", len(long_tail_issues))


if __name__ == "__main__":
    main()
