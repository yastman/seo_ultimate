#!/usr/bin/env python3
"""
compare_raw_clean.py â€” Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ CSV ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ¸ Ñ _clean.json

ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ğ²ĞµÑÑŒ CSV Ğ¸ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ _clean.json Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸.
ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ: Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ/ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ñ‹Ğµ ĞºĞ»ÑÑ‡Ğ¸, Ğ¸Ğ·Ğ¼ĞµĞ½Ñ‘Ğ½Ğ½Ñ‹Ğµ volumes.

Usage:
    python3 scripts/compare_raw_clean.py              # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ
    python3 scripts/compare_raw_clean.py --fix        # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ
    python3 scripts/compare_raw_clean.py aktivnaya-pena  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¾Ğ´Ğ½Ñƒ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ
"""

import csv
import json
import sys
from pathlib import Path

# Paths
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
SEMANTICS_CSV = PROJECT_ROOT / "Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° _Ultimate.csv"
CATEGORIES_DIR = PROJECT_ROOT / "categories"

# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· CSV â†’ slug ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸
CSV_TO_SLUG = {
    # L3 ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸
    "ĞĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿ĞµĞ½Ğ°": "aktivnaya-pena",
    "Ğ”Ğ»Ñ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ¹ĞºĞ¸": "dlya-ruchnoy-moyki",
    "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ĞµĞ»Ğ¸ ÑÑ‚ĞµĞºĞ¾Ğ»": "ochistiteli-stekol",
    "Ğ“Ğ»Ğ¸Ğ½Ğ° Ğ¸ Ğ°Ğ²Ñ‚Ğ¾ÑĞºÑ€Ğ°Ğ±Ñ‹": "glina-i-avtoskraby",
    "ĞĞ½Ñ‚Ğ¸Ğ¼Ğ¾ÑˆĞºĞ°": "antimoshka",
    "ĞĞ½Ñ‚Ğ¸Ğ±Ğ¸Ñ‚ÑƒĞ¼": "antibitum",
    "Ğ§ĞµÑ€Ğ½Ğ¸Ñ‚ĞµĞ»Ğ¸ ÑˆĞ¸Ğ½": "cherniteli-shin",
    "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ĞµĞ»Ğ¸ Ğ´Ğ¸ÑĞºĞ¾Ğ²": "ochistiteli-diskov",
    "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ĞµĞ»Ğ¸ ÑˆĞ¸Ğ½": "ochistiteli-shin",
    "ĞĞ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ñ‹ Tornador": "apparaty-tornador",
    "ĞœĞµÑ…Ğ¾Ğ²Ñ‹Ğµ": "mekhovye",
    "ĞŸĞ¾Ñ€Ğ¾Ğ»Ğ¾Ğ½Ğ¾Ğ²Ñ‹Ğµ": "porolonovye",
    "ĞĞ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸": "nabory-dlya-moyki",
    "ĞĞ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸": "nabory-dlya-polirovki",
    "ĞĞ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ ÑƒÑ…Ğ¾Ğ´Ğ° Ğ·Ğ° ĞºĞ¾Ğ¶ĞµĞ¹": "nabory-dlya-kozhi",
    "ĞĞ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ñ…Ğ¸Ğ¼Ñ‡Ğ¸ÑÑ‚ĞºĞ¸": "nabory-dlya-khimchistki",
    "ĞŸĞ¾Ğ´Ğ°Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹": "podarochnye-nabory",
    # L2 ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (Ğ² CSV ÑÑ‚Ğ¾ L2: ...)
    "ĞĞ²Ñ‚Ğ¾ÑˆĞ°Ğ¼Ğ¿ÑƒĞ½Ğ¸": "avtoshampuni",
    "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ĞµĞ»Ğ¸ Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»Ñ": "ochistiteli-dvigatelya",
    "ĞĞ±ĞµĞ·Ğ¶Ğ¸Ñ€Ğ¸Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸": "obezzhirivateli",
    "ĞœĞ°Ğ»ÑÑ€Ğ½Ğ¸Ğ¹ Ğ¡ĞºĞ¾Ñ‚Ñ‡": "malyarnyy-skotch",
    "ĞœĞ¸ĞºÑ€Ğ¾Ñ„Ğ¸Ğ±Ñ€Ğ° Ğ¸ Ñ‚Ñ€ÑĞ¿ĞºĞ¸": "mikrofibra-i-tryapki",
    "Ğ©ĞµÑ‚ĞºĞ¸ Ğ¸ ĞºĞ¸ÑÑ‚Ğ¸": "shchetki-i-kisti",
    "Ğ“ÑƒĞ±ĞºĞ¸ Ğ¸ Ğ²Ğ°Ñ€ĞµĞ¶ĞºĞ¸": "gubki-i-varezhki",
    "Ğ Ğ°ÑĞ¿Ñ‹Ğ»Ğ¸Ñ‚ĞµĞ»Ğ¸ Ğ¸ Ğ¿ĞµĞ½Ğ½Ğ¸ĞºĞ¸": "raspyliteli-i-penniki",
    "ĞĞºÑĞµÑÑÑƒĞ°Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ½Ğ°Ğ½ĞµÑĞµĞ½Ğ¸Ñ ÑÑ€ĞµĞ´ÑÑ‚Ğ²": "aksessuary-dlya-naneseniya",
    "Ğ’ĞµĞ´Ñ€Ğ° Ğ¸ ĞµĞ¼ĞºĞ¾ÑÑ‚Ğ¸": "vedra-i-emkosti",
    "ĞŸĞ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ°ÑˆĞ¸Ğ½ĞºĞ¸": "polirovalnye-mashinki",
    "ĞŸĞ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°ÑÑ‚Ñ‹": "polirovalnye-pasty",
    "ĞŸĞ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºÑ€ÑƒĞ³Ğ¸": "polirovalnye-krugi",
    "ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ·Ğ°Ğ¿Ğ°Ñ…Ğ°": "neytralizatory-zapakha",
    "ĞŸĞ¾Ğ»Ğ¸Ñ€Ğ¾Ğ»Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ»Ğ°ÑÑ‚Ğ¸ĞºĞ°": "poliroli-dlya-plastika",
    "Ğ¡Ñ€ĞµĞ´ÑÑ‚Ğ²Ğ° Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ¸": "sredstva-dlya-kozhi",
    "Ğ’Ğ¾ÑĞºĞ¸": "voski",
    "ĞšĞµÑ€Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¸ Ğ¶Ğ¸Ğ´ĞºĞ¾Ğµ ÑÑ‚ĞµĞºĞ»Ğ¾": "keramika-i-zhidkoe-steklo",
    "ĞšĞ²Ğ¸Ğº-Ğ´ĞµÑ‚ĞµĞ¹Ğ»ĞµÑ€Ñ‹": "kvik-deteylery",
    "ĞĞ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹Ğ»Ğ¸Ğ½Ğ³Ğ°": "nabory-dlya-deteylinga",
    "Ğ¡Ñ€ĞµĞ´ÑÑ‚Ğ²Ğ° Ğ´Ğ»Ñ ÑÑ‚ĞµĞºĞ¾Ğ»": "sredstva-dlya-stekol",
    "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ĞµĞ»Ğ¸ ĞºÑƒĞ·Ğ¾Ğ²Ğ°": "ochistiteli-kuzova",
    "Ğ¡Ñ€ĞµĞ´ÑÑ‚Ğ²Ğ° Ğ´Ğ»Ñ Ğ´Ğ¸ÑĞºĞ¾Ğ² Ğ¸ ÑˆĞ¸Ğ½": "sredstva-dlya-diskov-i-shin",
    "ĞĞ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ": "oborudovanie",
    # L1 ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (Ñ…Ğ°Ğ±Ñ‹) - Ğ² CSV ÑÑ‚Ğ¾ L1: ...
    "ĞœĞ¾Ğ¹ĞºĞ° Ğ¸ Ğ­ĞºÑÑ‚ĞµÑ€ÑŒĞµÑ€": "moyka-i-eksteryer",
    "ĞĞºÑĞµÑÑÑƒĞ°Ñ€Ñ‹": "aksessuary",
    "ĞŸĞ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°": "polirovka",
    "Ğ£Ñ…Ğ¾Ğ´ Ğ·Ğ° Ğ¸Ğ½Ñ‚ĞµÑ€ÑŒĞµÑ€Ğ¾Ğ¼": "ukhod-za-interyerom",
    "Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ": "zashchitnye-pokrytiya",
    # SEO-Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ (Ğ² CSV ÑÑ‚Ğ¾ SEO-Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€: ...)
    "Ğ¡ Ğ²Ğ¾ÑĞºĞ¾Ğ¼": "s-voskom",
    "ĞšĞ¸ÑĞ»Ğ¾Ñ‚Ğ½Ñ‹Ğ¹": "kislotnyy-shampun",
    "ĞĞºĞºÑƒĞ¼ÑƒĞ»ÑÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ": "akkumulyatornye-mashinki",
    "Ğ¢Ğ²ĞµÑ€Ğ´Ñ‹Ğ¹": "tverdyy-vosk",
    "Ğ–Ğ¸Ğ´ĞºĞ¸Ğ¹ (Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹)": "zhidkiy-vosk",
    "Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸": "mikrofibra-dlya-polirovki",
    "Ğ´Ğ»Ñ ÑÑ‚ĞµĞºĞ¾Ğ»": "mikrofibra-dlya-stekol",
    # Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸ (Ğ±ĞµĞ· Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑĞ° L Ğ¸Ğ»Ğ¸ SEO-)
    "ĞĞ¼Ñ‹Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ": "omyvatel",
    "ĞĞ½Ñ‚Ğ¸Ğ´Ğ¾Ğ¶Ğ´ÑŒ": "antidozhd",
    "Ğ”Ğ»Ñ Ñ…Ğ¸Ğ¼Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ ÑĞ°Ğ»Ğ¾Ğ½Ğ°": "dlya-khimchistki-salona",
    "ĞŸÑÑ‚Ğ½Ğ¾Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸": "pyatnovyvoditeli",
    "Ğ£Ñ…Ğ¾Ğ´ Ğ·Ğ° ĞºĞ¾Ğ¶ĞµĞ¹": "ukhod-za-kozhey",
    "Ğ§Ğ¸ÑÑ‚ĞºĞ° ĞºĞ¾Ğ¶Ğ¸": "chistka-kozhi",
    "ĞŸĞ¾Ğ»Ğ¸Ñ€Ğ¾Ğ»ÑŒ Ğ´Ğ»Ñ ÑÑ‚ĞµĞºĞ»Ğ°": "polirol-dlya-stekla",
    "Ğ¡Ğ¸Ğ»Ğ°Ğ½Ñ‚Ñ‹": "silanty",
    "Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ´Ğ»Ñ ĞºĞ¾Ğ»ĞµÑ": "zashchitnoe-pokrytie-dlya-koles",
    "Ğ”Ğ»Ñ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ Ğ¿Ğ»Ğ°ÑÑ‚Ğ¸ĞºĞ° Ğ¸ Ñ€ĞµĞ·Ğ¸Ğ½Ñ‹": "dlya-vneshnego-plastika",
    "Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ": "glavnaya",
    "ĞĞ°Ğ±Ğ¾Ñ€Ñ‹": "nabory",
    "ĞĞ¿Ñ‚": "opt",
    # ĞŸĞ¾Ğ´Ğ±Ğ»Ğ¾ĞºĞ¸ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ L2 (Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ñ‹ Ğ² ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸)
    "Ñ‚Ñ€ÑĞ¿ĞºĞ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾": "mikrofibra-i-tryapki",
    "Ñ‚Ñ€ÑĞ¿ĞºĞ° Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¸Ğ±Ñ€Ğ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾": "mikrofibra-i-tryapki",
    "Ñ‚Ñ€ÑĞ¿ĞºĞ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾ Ğ±ĞµĞ· Ñ€Ğ°Ğ·Ğ²Ğ¾Ğ´Ğ¾Ğ²": "mikrofibra-i-tryapki",
    "Ğ¿Ğ¾Ğ»Ğ¾Ñ‚ĞµĞ½Ñ†Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¸Ğ±Ñ€Ğ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾": "mikrofibra-i-tryapki",
    "Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¸Ğ±Ñ€Ğ° Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "mikrofibra-i-tryapki",
    "ÑÑƒĞ¿ĞµÑ€ Ğ²Ğ¿Ğ¸Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ°Ñ Ñ‚Ñ€ÑĞ¿ĞºĞ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾": "mikrofibra-i-tryapki",
    "Ñ‚Ñ€ÑĞ¿ĞºĞ° Ğ´Ğ»Ñ ÑÑ‚ĞµĞºĞ»Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ": "mikrofibra-i-tryapki",
    "Ñ‚Ñ€ÑĞ¿ĞºĞ° Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‚Ğ¸Ñ€Ğ°Ğ½Ğ¸Ñ Ğ°Ğ²Ñ‚Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¼Ğ¾Ğ¹ĞºĞ¸": "mikrofibra-i-tryapki",
    "Ñ‚Ñ€ÑĞ¿ĞºĞ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "mikrofibra-dlya-polirovki",
    "Ñ‰ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "shchetki-i-kisti",
    "Ñ‰ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ": "shchetki-i-kisti",
    "Ñ‰ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ¼Ñ‹Ñ‚ÑŒÑ Ğ¼Ğ°ÑˆĞ¸Ğ½Ñ‹": "shchetki-i-kisti",
    "ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ Ñ‰ĞµÑ‚ĞºĞ¸ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹Ğ»Ğ¸Ğ½Ğ³Ğ°": "shchetki-i-kisti",
    "Ñ‰ĞµÑ‚ĞºĞ¸ Ğ´Ğ»Ñ Ñ…Ğ¸Ğ¼Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "shchetki-i-kisti",
    "Ñ‰ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ ÑĞ°Ğ»Ğ¾Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾": "shchetki-i-kisti",
    "Ñ‰ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ´Ğ¸ÑĞºĞ¾Ğ² Ğ°Ğ²Ñ‚Ğ¾": "shchetki-i-kisti",
    "ĞºĞ¸ÑÑ‚Ğ¾Ñ‡ĞºĞ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "shchetki-i-kisti",
    "ĞºĞ¸ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "shchetki-i-kisti",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ñ…Ğ¸Ğ¼Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ": "nabory-dlya-khimchistki",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ñ…Ğ¸Ğ¼Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ": "nabory",
    "Ğ¿Ğ¾Ğ´Ğ°Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾": "podarochnye-nabory",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ ÑƒĞ±Ğ¾Ñ€ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ": "nabory",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾": "nabory",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹Ğ»Ğ¸Ğ½Ğ³Ğ°": "nabory-dlya-deteylinga",
    "Ğ¿Ğ¾Ğ´Ğ°Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¼ÑƒĞ¶Ñ‡Ğ¸Ğ½ Ğ² Ğ¼Ğ°ÑˆĞ¸Ğ½Ñƒ": "podarochnye-nabory",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "nabory-dlya-moyki",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ ÑĞ°Ğ»Ğ¾Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾": "nabory-dlya-khimchistki",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ ÑƒÑ…Ğ¾Ğ´Ğ° Ğ·Ğ° Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ¾Ğ¹": "nabory",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ ĞºÑ€ÑƒĞ³Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾": "nabory-dlya-polirovki",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ ĞºĞ¸ÑÑ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹Ğ»Ğ¸Ğ½Ğ³Ğ°": "nabory-dlya-deteylinga",
    "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ñ‚Ñ€ÑĞ¿Ğ¾Ğº Ğ´Ğ»Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½Ñ‹": "nabory-dlya-moyki",
    "ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹": "oborudovanie",
    "Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ…Ğ¸Ğ¼Ğ¸Ğ¸ ÑƒĞºÑ€Ğ°Ğ¸Ğ½Ğ°": "opt",
}

# Create SLUG_TO_CSV prioritizing L1/L2/L3 blocks over sub-blocks
PRIORITY_MAPPINGS = {
    "mikrofibra-i-tryapki": "ĞœĞ¸ĞºÑ€Ğ¾Ñ„Ğ¸Ğ±Ñ€Ğ° Ğ¸ Ñ‚Ñ€ÑĞ¿ĞºĞ¸",
    "shchetki-i-kisti": "Ğ©ĞµÑ‚ĞºĞ¸ Ğ¸ ĞºĞ¸ÑÑ‚Ğ¸",
    "nabory-dlya-moyki": "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ¹ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾",
    "nabory-dlya-polirovki": "Ğ½Ğ°Ğ±Ğ¾Ñ€ ĞºÑ€ÑƒĞ³Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾",
    "nabory-dlya-khimchistki": "Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ñ…Ğ¸Ğ¼Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ",
    "nabory-dlya-deteylinga": "Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹Ğ»Ğ¸Ğ½Ğ³Ğ°",
    "podarochnye-nabory": "Ğ¿Ğ¾Ğ´Ğ°Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¼ÑƒĞ¶Ñ‡Ğ¸Ğ½ Ğ² Ğ¼Ğ°ÑˆĞ¸Ğ½Ñƒ",
}

SLUG_TO_CSV = {v: k for k, v in CSV_TO_SLUG.items()}
# Override with priority mappings
SLUG_TO_CSV.update(PRIORITY_MAPPINGS)


def parse_csv_keywords() -> dict[str, list[dict]]:
    """
    ĞŸĞ°Ñ€ÑĞ¸Ñ‚ CSV Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ²ÑĞµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ°Ğ¼.

    Returns:
        {
            "ĞĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿ĞµĞ½Ğ°": [{"keyword": "...", "volume": 1300}, ...],
            ...
        }
    """
    blocks: dict[str, list[dict]] = {}
    current_block: str | None = None

    with open(SEMANTICS_CSV, encoding="utf-8") as f:
        reader = csv.reader(f)
        for row in reader:
            if not row or not row[0].strip():
                continue

            phrase = row[0].strip()
            count_str = row[1].strip() if len(row) > 1 else ""
            volume_str = row[2].strip() if len(row) > 2 else ""

            # Detect block headers
            if phrase.startswith("L1:"):
                block_name = phrase.replace("L1:", "").strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            if phrase.startswith("L2:"):
                block_name = phrase.replace("L2:", "").strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            if phrase.startswith("L3:"):
                block_name = phrase.replace("L3:", "").strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            if phrase.startswith("SEO-Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€:"):
                block_name = phrase.replace("SEO-Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€:", "").strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            # Special blocks (name with count, no volume)
            if count_str and count_str.replace("/", "").isdigit() and not volume_str:
                # This is a block header like "ĞĞ¼Ñ‹Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ,35," or "ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ,16,"
                if phrase.lower() != "ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ":
                    current_block = phrase
                    if current_block not in blocks:
                        blocks[current_block] = []
                continue

            # Skip if no current block
            if not current_block:
                continue

            # Parse keyword with volume
            if volume_str.isdigit():
                volume = int(volume_str)
                blocks[current_block].append({"keyword": phrase, "volume": volume})

    return blocks


def read_clean_json(slug: str) -> dict | None:
    """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ _clean.json Ğ´Ğ»Ñ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸."""
    path = CATEGORIES_DIR / slug / "data" / f"{slug}_clean.json"
    if not path.exists():
        return None

    with open(path, encoding="utf-8") as f:
        return json.load(f)


def get_clean_keywords(clean_data: dict) -> list[dict]:
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ²ÑĞµ ĞºĞ»ÑÑ‡Ğ¸ Ğ¸Ğ· _clean.json Ğ² Ğ¿Ğ»Ğ¾ÑĞºĞ¸Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº."""
    keywords = []
    kw_data = clean_data.get("keywords", {})

    for category in ["primary", "secondary", "supporting", "commercial"]:
        for kw in kw_data.get(category, []):
            keywords.append({"keyword": kw["keyword"], "volume": kw["volume"]})

    return keywords


def compare_keywords(csv_kws: list[dict], clean_kws: list[dict]) -> dict:
    """
    Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ»ÑÑ‡Ğ¸ Ğ¸Ğ· CSV Ñ _clean.json.

    Returns:
        {
            'added': [...],      # Ğ² clean, Ğ½Ğ¾ Ğ½ĞµÑ‚ Ğ² csv
            'removed': [...],    # Ğ² csv, Ğ½Ğ¾ Ğ½ĞµÑ‚ Ğ² clean
            'volume_changed': [...],  # Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ volumes
            'match': True/False
        }
    """
    csv_dict = {kw["keyword"]: kw["volume"] for kw in csv_kws}
    clean_dict = {kw["keyword"]: kw["volume"] for kw in clean_kws}

    added = []
    removed = []
    volume_changed = []

    # Keywords in clean but not in csv
    for kw, vol in clean_dict.items():
        if kw not in csv_dict:
            added.append({"keyword": kw, "volume": vol})
        elif csv_dict[kw] != vol:
            volume_changed.append({"keyword": kw, "csv_volume": csv_dict[kw], "clean_volume": vol})

    # Keywords in csv but not in clean
    for kw, vol in csv_dict.items():
        if kw not in clean_dict:
            removed.append({"keyword": kw, "volume": vol})

    return {
        "added": added,
        "removed": removed,
        "volume_changed": volume_changed,
        "match": not (added or removed or volume_changed),
    }


def fix_clean_json(slug: str, clean_data: dict, csv_kws: list[dict], result: dict) -> tuple[bool, str]:
    """
    Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ _clean.json:
    - Ğ£Ğ´Ğ°Ğ»ÑĞµÑ‚ ĞºĞ»ÑÑ‡Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ² CSV (added)
    - Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ volumes Ğ½Ğ° Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· CSV (volume_changed)

    Returns:
        (success, message)
    """
    # Build CSV lookup (not needed, we have volume_fixes)
    # csv_dict = {kw["keyword"]: kw["volume"] for kw in csv_kws}

    # Keywords to remove (added = not in CSV)
    added_kws = {kw["keyword"] for kw in result["added"]}

    # Keywords with wrong volumes
    volume_fixes = {kw["keyword"]: kw["csv_volume"] for kw in result["volume_changed"]}

    changes = []
    kw_data = clean_data.get("keywords", {})

    for category in ["primary", "secondary", "supporting", "commercial"]:
        if category not in kw_data:
            continue

        # original_count = len(kw_data[category])

        # Filter out added keywords and fix volumes
        new_list = []
        for kw in kw_data[category]:
            keyword = kw["keyword"]

            # Skip keywords not in CSV
            if keyword in added_kws:
                changes.append(f"Removed '{keyword}' from {category}")
                continue

            # Fix volume if needed
            if keyword in volume_fixes:
                old_vol = kw["volume"]
                new_vol = volume_fixes[keyword]
                kw["volume"] = new_vol
                changes.append(f"Fixed volume '{keyword}': {old_vol} â†’ {new_vol}")

            new_list.append(kw)

        kw_data[category] = new_list

    # Update stats
    total_kws = sum(len(kw_data.get(cat, [])) for cat in ["primary", "secondary", "supporting", "commercial"])
    total_vol = sum(
        kw["volume"] for cat in ["primary", "secondary", "supporting", "commercial"] for kw in kw_data.get(cat, [])
    )

    if "stats" in clean_data:
        clean_data["stats"]["after"] = total_kws
        clean_data["stats"]["total_volume"] = total_vol

    if not changes:
        return False, "No changes needed"

    # Write back
    path = CATEGORIES_DIR / slug / "data" / f"{slug}_clean.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(clean_data, f, ensure_ascii=False, indent=2)

    return True, f"{len(changes)} changes: " + "; ".join(changes[:3]) + ("..." if len(changes) > 3 else "")


def main():
    fix_mode = "--fix" in sys.argv
    target_slug = None

    for arg in sys.argv[1:]:
        if not arg.startswith("--"):
            target_slug = arg
            break

    print(f"ğŸ“– Reading CSV: {SEMANTICS_CSV}")
    csv_blocks = parse_csv_keywords()
    print(f"âœ… Found {len(csv_blocks)} blocks in CSV\n")

    # Get all category slugs
    if target_slug:
        slugs = [target_slug]
    else:
        slugs = sorted([d.name for d in CATEGORIES_DIR.iterdir() if d.is_dir()])

    issues = []
    no_csv_data = []

    for slug in slugs:
        # Find corresponding CSV block
        csv_name = SLUG_TO_CSV.get(slug)
        csv_kws = csv_blocks.get(csv_name, []) if csv_name else []

        # Read clean.json
        clean_data = read_clean_json(slug)
        if not clean_data:
            print(f"âš ï¸  {slug}: No _clean.json found")
            continue

        clean_kws = get_clean_keywords(clean_data)

        if not csv_kws:
            print(f"â“ {slug}: No CSV data (csv_name={csv_name})")
            no_csv_data.append(slug)
            continue

        # Compare
        result = compare_keywords(csv_kws, clean_kws)

        if result["match"]:
            print(f"âœ… {slug}: OK ({len(clean_kws)} keywords)")
        else:
            # Only show issues for Added and Volume changed (not Removed - that's expected)
            has_real_issues = result["added"] or result["volume_changed"]

            if has_real_issues:
                print(f"âŒ {slug}: MISMATCH")
            else:
                print(f"âœ… {slug}: OK ({len(clean_kws)} keywords, {len(result['removed'])} filtered)")
                continue

            if result["added"]:
                print(f"   Added (not in CSV): {len(result['added'])}")
                for kw in result["added"][:3]:
                    print(f"      + {kw['keyword']} ({kw['volume']})")
                if len(result["added"]) > 3:
                    print(f"      ... and {len(result['added']) - 3} more")

            if result["volume_changed"]:
                print(f"   Volume changed: {len(result['volume_changed'])}")
                for kw in result["volume_changed"][:3]:
                    print(f"      ~ {kw['keyword']}: {kw['csv_volume']} â†’ {kw['clean_volume']}")
                if len(result["volume_changed"]) > 3:
                    print(f"      ... and {len(result['volume_changed']) - 3} more")

            issues.append({"slug": slug, "result": result, "csv_kws": csv_kws, "clean_data": clean_data})

    print(f"\n{'=' * 60}")
    ok_count = len(slugs) - len(issues) - len(no_csv_data)
    print(f"Summary: {ok_count} OK, {len(issues)} with issues, {len(no_csv_data)} no CSV data")

    if fix_mode and issues:
        print(f"\nğŸ”§ Fixing {len(issues)} categories...")
        fixed = 0
        for issue in issues:
            slug = issue["slug"]
            success, msg = fix_clean_json(slug, issue["clean_data"], issue["csv_kws"], issue["result"])
            if success:
                print(f"   âœ… {slug}: {msg}")
                fixed += 1
            else:
                print(f"   âš ï¸  {slug}: {msg}")
        print(f"\nâœ… Fixed {fixed} categories")
    elif issues and not fix_mode:
        print("\nğŸ’¡ Run with --fix to auto-fix issues")


if __name__ == "__main__":
    main()
