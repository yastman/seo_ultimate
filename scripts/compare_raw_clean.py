#!/usr/bin/env python3
"""
compare_raw_clean.py ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CSV —Å–µ–º–∞–Ω—Ç–∏–∫–∏ —Å _clean.json

–ü–∞—Ä—Å–∏—Ç –≤–µ—Å—å CSV –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ _clean.json —Ñ–∞–π–ª–∞–º–∏.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è: –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ/—É–¥–∞–ª—ë–Ω–Ω—ã–µ –∫–ª—é—á–∏, –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ volumes.

Usage:
    python3 scripts/compare_raw_clean.py              # –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
    python3 scripts/compare_raw_clean.py --fix        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
    python3 scripts/compare_raw_clean.py aktivnaya-pena  # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–¥–Ω—É –∫–∞—Ç–µ–≥–æ—Ä–∏—é
"""

import csv
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Paths
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
SEMANTICS_CSV = PROJECT_ROOT / "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ _Ultimate.csv"
CATEGORIES_DIR = PROJECT_ROOT / "categories"

# –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏–π –∏–∑ CSV ‚Üí slug –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
CSV_TO_SLUG = {
    # L3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    "–ê–∫—Ç–∏–≤–Ω–∞—è –ø–µ–Ω–∞": "aktivnaya-pena",
    "–î–ª—è —Ä—É—á–Ω–æ–π –º–æ–π–∫–∏": "dlya-ruchnoy-moyki",
    "–û—á–∏—Å—Ç–∏—Ç–µ–ª–∏ —Å—Ç–µ–∫–æ–ª": "ochistiteli-stekol",
    "–ì–ª–∏–Ω–∞ –∏ –∞–≤—Ç–æ—Å–∫—Ä–∞–±—ã": "glina-i-avtoskraby",
    "–ê–Ω—Ç–∏–º–æ—à–∫–∞": "antimoshka",
    "–ê–Ω—Ç–∏–±–∏—Ç—É–º": "antibitum",
    "–ß–µ—Ä–Ω–∏—Ç–µ–ª–∏ —à–∏–Ω": "cherniteli-shin",
    "–û—á–∏—Å—Ç–∏—Ç–µ–ª–∏ –¥–∏—Å–∫–æ–≤": "ochistiteli-diskov",
    "–û—á–∏—Å—Ç–∏—Ç–µ–ª–∏ —à–∏–Ω": "ochistiteli-shin",
    "–ê–ø–ø–∞—Ä–∞—Ç—ã Tornador": "apparaty-tornador",
    "–ú–µ—Ö–æ–≤—ã–µ": "mekhovye",
    "–ü–æ—Ä–æ–ª–æ–Ω–æ–≤—ã–µ": "porolonovye",
    "–ù–∞–±–æ—Ä—ã –¥–ª—è –º–æ–π–∫–∏": "nabory-dlya-moyki",
    "–ù–∞–±–æ—Ä—ã –¥–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏": "nabory-dlya-polirovki",
    "–ù–∞–±–æ—Ä—ã –¥–ª—è —É—Ö–æ–¥–∞ –∑–∞ –∫–æ–∂–µ–π": "nabory-dlya-kozhi",
    "–ù–∞–±–æ—Ä—ã –¥–ª—è —Ö–∏–º—á–∏—Å—Ç–∫–∏": "nabory-dlya-khimchistki",
    "–ü–æ–¥–∞—Ä–æ—á–Ω—ã–µ –Ω–∞–±–æ—Ä—ã": "podarochnye-nabory",

    # L2 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–≤ CSV —ç—Ç–æ L2: ...)
    "–ê–≤—Ç–æ—à–∞–º–ø—É–Ω–∏": "avtoshampuni",
    "–û—á–∏—Å—Ç–∏—Ç–µ–ª–∏ –¥–≤–∏–≥–∞—Ç–µ–ª—è": "ochistiteli-dvigatelya",
    "–û–±–µ–∑–∂–∏—Ä–∏–≤–∞—Ç–µ–ª–∏": "obezzhirivateli",
    "–ú–∞–ª—è—Ä–Ω–∏–π –°–∫–æ—Ç—á": "malyarnyy-skotch",
    "–ú–∏–∫—Ä–æ—Ñ–∏–±—Ä–∞ –∏ —Ç—Ä—è–ø–∫–∏": "mikrofibra-i-tryapki",
    "–©–µ—Ç–∫–∏ –∏ –∫–∏—Å—Ç–∏": "shchetki-i-kisti",
    "–ì—É–±–∫–∏ –∏ –≤–∞—Ä–µ–∂–∫–∏": "gubki-i-varezhki",
    "–†–∞—Å–ø—ã–ª–∏—Ç–µ–ª–∏ –∏ –ø–µ–Ω–Ω–∏–∫–∏": "raspyliteli-i-penniki",
    "–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã –¥–ª—è –Ω–∞–Ω–µ—Å–µ–Ω–∏—è —Å—Ä–µ–¥—Å—Ç–≤": "aksessuary-dlya-naneseniya",
    "–í–µ–¥—Ä–∞ –∏ –µ–º–∫–æ—Å—Ç–∏": "vedra-i-emkosti",
    "–ü–æ–ª–∏—Ä–æ–≤–∞–ª—å–Ω—ã–µ –º–∞—à–∏–Ω–∫–∏": "polirovalnye-mashinki",
    "–ü–æ–ª–∏—Ä–æ–≤–∞–ª—å–Ω—ã–µ –ø–∞—Å—Ç—ã": "polirovalnye-pasty",
    "–ü–æ–ª–∏—Ä–æ–≤–∞–ª—å–Ω—ã–µ –∫—Ä—É–≥–∏": "polirovalnye-krugi",
    "–ù–µ–π—Ç—Ä–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –∑–∞–ø–∞—Ö–∞": "neytralizatory-zapakha",
    "–ü–æ–ª–∏—Ä–æ–ª–∏ –¥–ª—è –ø–ª–∞—Å—Ç–∏–∫–∞": "poliroli-dlya-plastika",
    "–°—Ä–µ–¥—Å—Ç–≤–∞ –¥–ª—è –∫–æ–∂–∏": "sredstva-dlya-kozhi",
    "–í–æ—Å–∫–∏": "voski",
    "–ö–µ—Ä–∞–º–∏–∫–∞ –∏ –∂–∏–¥–∫–æ–µ —Å—Ç–µ–∫–ª–æ": "keramika-i-zhidkoe-steklo",
    "–ö–≤–∏–∫-–¥–µ—Ç–µ–π–ª–µ—Ä—ã": "kvik-deteylery",
    "–ù–∞–±–æ—Ä—ã –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞": "nabory-dlya-deteylinga",
    "–°—Ä–µ–¥—Å—Ç–≤–∞ –¥–ª—è —Å—Ç–µ–∫–æ–ª": "sredstva-dlya-stekol",
    "–û—á–∏—Å—Ç–∏—Ç–µ–ª–∏ –∫—É–∑–æ–≤–∞": "ochistiteli-kuzova",
    "–°—Ä–µ–¥—Å—Ç–≤–∞ –¥–ª—è –¥–∏—Å–∫–æ–≤ –∏ —à–∏–Ω": "sredstva-dlya-diskov-i-shin",
    "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ": "oborudovanie",

    # L1 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Ö–∞–±—ã) - –≤ CSV —ç—Ç–æ L1: ...
    "–ú–æ–π–∫–∞ –∏ –≠–∫—Å—Ç–µ—Ä—å–µ—Ä": "moyka-i-eksteryer",
    "–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã": "aksessuary",
    "–ü–æ–ª–∏—Ä–æ–≤–∫–∞": "polirovka",
    "–£—Ö–æ–¥ –∑–∞ –∏–Ω—Ç–µ—Ä—å–µ—Ä–æ–º": "ukhod-za-interyerom",
    "–ó–∞—â–∏—Ç–Ω—ã–µ –ø–æ–∫—Ä—ã—Ç–∏—è": "zashchitnye-pokrytiya",

    # SEO-—Ñ–∏–ª—å—Ç—Ä—ã (–≤ CSV —ç—Ç–æ SEO-–§–∏–ª—å—Ç—Ä: ...)
    "–° –≤–æ—Å–∫–æ–º": "s-voskom",
    "–ö–∏—Å–ª–æ—Ç–Ω—ã–π": "kislotnyy-shampun",
    "–ê–∫–∫—É–º—É–ª—è—Ç–æ—Ä–Ω–∞—è": "akkumulyatornye-mashinki",
    "–¢–≤–µ—Ä–¥—ã–π": "tverdyy-vosk",
    "–ñ–∏–¥–∫–∏–π (–±—ã—Å—Ç—Ä—ã–π)": "zhidkiy-vosk",
    "–î–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏": "mikrofibra-dlya-polirovki",
    "–¥–ª—è —Å—Ç–µ–∫–æ–ª": "mikrofibra-dlya-stekol",

    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ L –∏–ª–∏ SEO-)
    "–û–º—ã–≤–∞—Ç–µ–ª—å": "omyvatel",
    "–ê–Ω—Ç–∏–¥–æ–∂–¥—å": "antidozhd",
    "–î–ª—è —Ö–∏–º—á–∏—Å—Ç–∫–∏ —Å–∞–ª–æ–Ω–∞": "dlya-khimchistki-salona",
    "–ü—è—Ç–Ω–æ–≤—ã–≤–æ–¥–∏—Ç–µ–ª–∏": "pyatnovyvoditeli",
    "–£—Ö–æ–¥ –∑–∞ –∫–æ–∂–µ–π": "ukhod-za-kozhey",
    "–ß–∏—Å—Ç–∫–∞ –∫–æ–∂–∏": "chistka-kozhi",
    "–ü–æ–ª–∏—Ä–æ–ª—å –¥–ª—è —Å—Ç–µ–∫–ª–∞": "polirol-dlya-stekla",
    "–°–∏–ª–∞–Ω—Ç—ã": "silanty",
    "–ó–∞—â–∏—Ç–Ω—ã–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–ª—è –∫–æ–ª–µ—Å": "zashchitnoe-pokrytie-dlya-koles",
    "–î–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –ø–ª–∞—Å—Ç–∏–∫–∞ –∏ —Ä–µ–∑–∏–Ω—ã": "dlya-vneshnego-plastika",
    "–ì–ª–∞–≤–Ω–∞—è": "glavnaya",
    "–ù–∞–±–æ—Ä—ã": "nabory",
    "–û–ø—Ç": "opt",

    # –ü–æ–¥–±–ª–æ–∫–∏ –≤–Ω—É—Ç—Ä–∏ L2 (–æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    "—Ç—Ä—è–ø–∫–∞ –¥–ª—è –∞–≤—Ç–æ": "mikrofibra-i-tryapki",
    "—Ç—Ä—è–ø–∫–∞ –º–∏–∫—Ä–æ—Ñ–∏–±—Ä–∞ –¥–ª—è –∞–≤—Ç–æ": "mikrofibra-i-tryapki",
    "—Ç—Ä—è–ø–∫–∞ –¥–ª—è –∞–≤—Ç–æ –±–µ–∑ —Ä–∞–∑–≤–æ–¥–æ–≤": "mikrofibra-i-tryapki",
    "–ø–æ–ª–æ—Ç–µ–Ω—Ü–µ –º–∏–∫—Ä–æ—Ñ–∏–±—Ä–∞ –¥–ª—è –∞–≤—Ç–æ": "mikrofibra-i-tryapki",
    "–º–∏–∫—Ä–æ—Ñ–∏–±—Ä–∞ –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ": "mikrofibra-i-tryapki",
    "—Å—É–ø–µ—Ä –≤–ø–∏—Ç—ã–≤–∞—é—â–∞—è —Ç—Ä—è–ø–∫–∞ –¥–ª—è –∞–≤—Ç–æ": "mikrofibra-i-tryapki",
    "—Ç—Ä—è–ø–∫–∞ –¥–ª—è —Å—Ç–µ–∫–ª–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è": "mikrofibra-i-tryapki",
    "—Ç—Ä—è–ø–∫–∞ –¥–ª—è –≤—ã—Ç–∏—Ä–∞–Ω–∏—è –∞–≤—Ç–æ –ø–æ—Å–ª–µ –º–æ–π–∫–∏": "mikrofibra-i-tryapki",
    "—Ç—Ä—è–ø–∫–∏ –¥–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ": "mikrofibra-dlya-polirovki",

    "—â–µ—Ç–∫–∞ –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ": "shchetki-i-kisti",
    "—â–µ—Ç–∫–∞ –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è": "shchetki-i-kisti",
    "—â–µ—Ç–∫–∞ –¥–ª—è –º—ã—Ç—å—è –º–∞—à–∏–Ω—ã": "shchetki-i-kisti",
    "–∫—É–ø–∏—Ç—å —â–µ—Ç–∫–∏ –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞": "shchetki-i-kisti",
    "—â–µ—Ç–∫–∏ –¥–ª—è —Ö–∏–º—á–∏—Å—Ç–∫–∏ –∞–≤—Ç–æ": "shchetki-i-kisti",
    "—â–µ—Ç–∫–∞ –¥–ª—è —Å–∞–ª–æ–Ω–∞ –∞–≤—Ç–æ": "shchetki-i-kisti",
    "—â–µ—Ç–∫–∞ –¥–ª—è –¥–∏—Å–∫–æ–≤ –∞–≤—Ç–æ": "shchetki-i-kisti",
    "–∫–∏—Å—Ç–æ—á–∫–∏ –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ": "shchetki-i-kisti",
    "–∫–∏—Å—Ç–∏ –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ": "shchetki-i-kisti",

    "–Ω–∞–±–æ—Ä –¥–ª—è —Ö–∏–º—á–∏—Å—Ç–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è": "nabory-dlya-khimchistki",
    "–Ω–∞–±–æ—Ä —Ö–∏–º–∏–∏ –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è": "nabory",
    "–ø–æ–¥–∞—Ä–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –∞–≤—Ç–æ": "podarochnye-nabory",
    "–Ω–∞–±–æ—Ä –¥–ª—è —É–±–æ—Ä–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è": "nabory",
    "–Ω–∞–±–æ—Ä—ã –¥–ª—è –∞–≤—Ç–æ": "nabory",
    "–Ω–∞–±–æ—Ä—ã –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞": "nabory-dlya-deteylinga",
    "–ø–æ–¥–∞—Ä–æ—á–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –¥–ª—è –º—É–∂—á–∏–Ω –≤ –º–∞—à–∏–Ω—É": "podarochnye-nabory",
    "–Ω–∞–±–æ—Ä –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ": "nabory-dlya-moyki",
    "–Ω–∞–±–æ—Ä –¥–ª—è —á–∏—Å—Ç–∫–∏ —Å–∞–ª–æ–Ω–∞ –∞–≤—Ç–æ": "nabory-dlya-khimchistki",
    "–Ω–∞–±–æ—Ä –¥–ª—è —É—Ö–æ–¥–∞ –∑–∞ –º–∞—à–∏–Ω–æ–π": "nabory",
    "–Ω–∞–±–æ—Ä –∫—Ä—É–≥–æ–≤ –¥–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ": "nabory-dlya-polirovki",
    "–Ω–∞–±–æ—Ä –∫–∏—Å—Ç–µ–π –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞": "nabory-dlya-deteylinga",
    "–Ω–∞–±–æ—Ä —Ç—Ä—è–ø–æ–∫ –¥–ª—è –º–∞—à–∏–Ω—ã": "nabory-dlya-moyki",

    "–∫—É–ø–∏—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π": "oborudovanie",
    "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏ –∞–≤—Ç–æ—Ö–∏–º–∏–∏ —É–∫—Ä–∞–∏–Ω–∞": "opt",
}

# Create SLUG_TO_CSV prioritizing L1/L2/L3 blocks over sub-blocks
PRIORITY_MAPPINGS = {
    "mikrofibra-i-tryapki": "–ú–∏–∫—Ä–æ—Ñ–∏–±—Ä–∞ –∏ —Ç—Ä—è–ø–∫–∏",
    "shchetki-i-kisti": "–©–µ—Ç–∫–∏ –∏ –∫–∏—Å—Ç–∏",
    "nabory-dlya-moyki": "–Ω–∞–±–æ—Ä –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ",
    "nabory-dlya-polirovki": "–Ω–∞–±–æ—Ä –∫—Ä—É–≥–æ–≤ –¥–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ",
    "nabory-dlya-khimchistki": "–Ω–∞–±–æ—Ä –¥–ª—è —Ö–∏–º—á–∏—Å—Ç–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è",
    "nabory-dlya-deteylinga": "–Ω–∞–±–æ—Ä—ã –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞",
    "podarochnye-nabory": "–ø–æ–¥–∞—Ä–æ—á–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –¥–ª—è –º—É–∂—á–∏–Ω –≤ –º–∞—à–∏–Ω—É",
}

SLUG_TO_CSV = {v: k for k, v in CSV_TO_SLUG.items()}
# Override with priority mappings
SLUG_TO_CSV.update(PRIORITY_MAPPINGS)


def parse_csv_keywords() -> Dict[str, List[Dict]]:
    """
    –ü–∞—Ä—Å–∏—Ç CSV –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø–æ –±–ª–æ–∫–∞–º.

    Returns:
        {
            "–ê–∫—Ç–∏–≤–Ω–∞—è –ø–µ–Ω–∞": [{"keyword": "...", "volume": 1300}, ...],
            ...
        }
    """
    blocks: Dict[str, List[Dict]] = {}
    current_block: Optional[str] = None

    with open(SEMANTICS_CSV, encoding='utf-8') as f:
        reader = csv.reader(f)
        for row in reader:
            if not row or not row[0].strip():
                continue

            phrase = row[0].strip()
            count_str = row[1].strip() if len(row) > 1 else ''
            volume_str = row[2].strip() if len(row) > 2 else ''

            # Detect block headers
            if phrase.startswith('L1:'):
                block_name = phrase.replace('L1:', '').strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            if phrase.startswith('L2:'):
                block_name = phrase.replace('L2:', '').strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            if phrase.startswith('L3:'):
                block_name = phrase.replace('L3:', '').strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            if phrase.startswith('SEO-–§–∏–ª—å—Ç—Ä:'):
                block_name = phrase.replace('SEO-–§–∏–ª—å—Ç—Ä:', '').strip()
                current_block = block_name
                if current_block not in blocks:
                    blocks[current_block] = []
                continue

            # Special blocks (name with count, no volume)
            if count_str and count_str.replace('/', '').isdigit() and not volume_str:
                # This is a block header like "–û–º—ã–≤–∞—Ç–µ–ª—å,35," or "–∫–∞—Ç–µ–≥–æ—Ä–∏—è,16,"
                if phrase.lower() != '–∫–∞—Ç–µ–≥–æ—Ä–∏—è':
                    current_block = phrase
                    if current_block not in blocks:
                        blocks[current_block] = []
                continue

            # Skip if no current block
            if not current_block:
                continue

            # Parse keyword with volume
            if volume_str.isdigit():
                volume = int(volume_str)
                blocks[current_block].append({
                    'keyword': phrase,
                    'volume': volume
                })

    return blocks


def read_clean_json(slug: str) -> Optional[Dict]:
    """–ß–∏—Ç–∞–µ—Ç _clean.json –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
    path = CATEGORIES_DIR / slug / "data" / f"{slug}_clean.json"
    if not path.exists():
        return None

    with open(path, encoding='utf-8') as f:
        return json.load(f)


def get_clean_keywords(clean_data: Dict) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∫–ª—é—á–∏ –∏–∑ _clean.json –≤ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫."""
    keywords = []
    kw_data = clean_data.get('keywords', {})

    for category in ['primary', 'secondary', 'supporting', 'commercial']:
        for kw in kw_data.get(category, []):
            keywords.append({
                'keyword': kw['keyword'],
                'volume': kw['volume']
            })

    return keywords


def compare_keywords(csv_kws: List[Dict], clean_kws: List[Dict]) -> Dict:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–ª—é—á–∏ –∏–∑ CSV —Å _clean.json.

    Returns:
        {
            'added': [...],      # –≤ clean, –Ω–æ –Ω–µ—Ç –≤ csv
            'removed': [...],    # –≤ csv, –Ω–æ –Ω–µ—Ç –≤ clean
            'volume_changed': [...],  # —Ä–∞–∑–Ω—ã–µ volumes
            'match': True/False
        }
    """
    csv_dict = {kw['keyword']: kw['volume'] for kw in csv_kws}
    clean_dict = {kw['keyword']: kw['volume'] for kw in clean_kws}

    added = []
    removed = []
    volume_changed = []

    # Keywords in clean but not in csv
    for kw, vol in clean_dict.items():
        if kw not in csv_dict:
            added.append({'keyword': kw, 'volume': vol})
        elif csv_dict[kw] != vol:
            volume_changed.append({
                'keyword': kw,
                'csv_volume': csv_dict[kw],
                'clean_volume': vol
            })

    # Keywords in csv but not in clean
    for kw, vol in csv_dict.items():
        if kw not in clean_dict:
            removed.append({'keyword': kw, 'volume': vol})

    return {
        'added': added,
        'removed': removed,
        'volume_changed': volume_changed,
        'match': not (added or removed or volume_changed)
    }


def fix_clean_json(slug: str, clean_data: Dict, csv_kws: List[Dict], result: Dict) -> Tuple[bool, str]:
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç _clean.json:
    - –£–¥–∞–ª—è–µ—Ç –∫–ª—é—á–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ CSV (added)
    - –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç volumes –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ CSV (volume_changed)

    Returns:
        (success, message)
    """
    # Build CSV lookup
    csv_dict = {kw['keyword']: kw['volume'] for kw in csv_kws}

    # Keywords to remove (added = not in CSV)
    added_kws = {kw['keyword'] for kw in result['added']}

    # Keywords with wrong volumes
    volume_fixes = {kw['keyword']: kw['csv_volume'] for kw in result['volume_changed']}

    changes = []
    kw_data = clean_data.get('keywords', {})

    for category in ['primary', 'secondary', 'supporting', 'commercial']:
        if category not in kw_data:
            continue

        original_count = len(kw_data[category])

        # Filter out added keywords and fix volumes
        new_list = []
        for kw in kw_data[category]:
            keyword = kw['keyword']

            # Skip keywords not in CSV
            if keyword in added_kws:
                changes.append(f"Removed '{keyword}' from {category}")
                continue

            # Fix volume if needed
            if keyword in volume_fixes:
                old_vol = kw['volume']
                new_vol = volume_fixes[keyword]
                kw['volume'] = new_vol
                changes.append(f"Fixed volume '{keyword}': {old_vol} ‚Üí {new_vol}")

            new_list.append(kw)

        kw_data[category] = new_list

    # Update stats
    total_kws = sum(len(kw_data.get(cat, [])) for cat in ['primary', 'secondary', 'supporting', 'commercial'])
    total_vol = sum(kw['volume'] for cat in ['primary', 'secondary', 'supporting', 'commercial'] for kw in kw_data.get(cat, []))

    if 'stats' in clean_data:
        clean_data['stats']['after'] = total_kws
        clean_data['stats']['total_volume'] = total_vol

    if not changes:
        return False, "No changes needed"

    # Write back
    path = CATEGORIES_DIR / slug / "data" / f"{slug}_clean.json"
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(clean_data, f, ensure_ascii=False, indent=2)

    return True, f"{len(changes)} changes: " + "; ".join(changes[:3]) + ("..." if len(changes) > 3 else "")


def main():
    fix_mode = '--fix' in sys.argv
    target_slug = None

    for arg in sys.argv[1:]:
        if not arg.startswith('--'):
            target_slug = arg
            break

    print(f"üìñ Reading CSV: {SEMANTICS_CSV}")
    csv_blocks = parse_csv_keywords()
    print(f"‚úÖ Found {len(csv_blocks)} blocks in CSV\n")

    # Get all category slugs
    if target_slug:
        slugs = [target_slug]
    else:
        slugs = sorted([d.name for d in CATEGORIES_DIR.iterdir() if d.is_dir()])

    issues = []
    no_csv_data = []

    for slug in slugs:
        # Find corresponding CSV block
        csv_name = SLUG_TO_CSV.get(slug)
        csv_kws = csv_blocks.get(csv_name, []) if csv_name else []

        # Read clean.json
        clean_data = read_clean_json(slug)
        if not clean_data:
            print(f"‚ö†Ô∏è  {slug}: No _clean.json found")
            continue

        clean_kws = get_clean_keywords(clean_data)

        if not csv_kws:
            print(f"‚ùì {slug}: No CSV data (csv_name={csv_name})")
            no_csv_data.append(slug)
            continue

        # Compare
        result = compare_keywords(csv_kws, clean_kws)

        if result['match']:
            print(f"‚úÖ {slug}: OK ({len(clean_kws)} keywords)")
        else:
            # Only show issues for Added and Volume changed (not Removed - that's expected)
            has_real_issues = result['added'] or result['volume_changed']

            if has_real_issues:
                print(f"‚ùå {slug}: MISMATCH")
            else:
                print(f"‚úÖ {slug}: OK ({len(clean_kws)} keywords, {len(result['removed'])} filtered)")
                continue

            if result['added']:
                print(f"   Added (not in CSV): {len(result['added'])}")
                for kw in result['added'][:3]:
                    print(f"      + {kw['keyword']} ({kw['volume']})")
                if len(result['added']) > 3:
                    print(f"      ... and {len(result['added']) - 3} more")

            if result['volume_changed']:
                print(f"   Volume changed: {len(result['volume_changed'])}")
                for kw in result['volume_changed'][:3]:
                    print(f"      ~ {kw['keyword']}: {kw['csv_volume']} ‚Üí {kw['clean_volume']}")
                if len(result['volume_changed']) > 3:
                    print(f"      ... and {len(result['volume_changed']) - 3} more")

            issues.append({
                'slug': slug,
                'result': result,
                'csv_kws': csv_kws,
                'clean_data': clean_data
            })

    print(f"\n{'='*60}")
    ok_count = len(slugs) - len(issues) - len(no_csv_data)
    print(f"Summary: {ok_count} OK, {len(issues)} with issues, {len(no_csv_data)} no CSV data")

    if fix_mode and issues:
        print(f"\nüîß Fixing {len(issues)} categories...")
        fixed = 0
        for issue in issues:
            slug = issue['slug']
            success, msg = fix_clean_json(
                slug,
                issue['clean_data'],
                issue['csv_kws'],
                issue['result']
            )
            if success:
                print(f"   ‚úÖ {slug}: {msg}")
                fixed += 1
            else:
                print(f"   ‚ö†Ô∏è  {slug}: {msg}")
        print(f"\n‚úÖ Fixed {fixed} categories")
    elif issues and not fix_mode:
        print(f"\nüí° Run with --fix to auto-fix issues")


if __name__ == "__main__":
    main()
