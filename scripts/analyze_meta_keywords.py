#!/usr/bin/env python3
"""–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ—Ç–∞-—Ç–µ–≥–æ–≤ –≥–ª–∞–≤–Ω—ã–º –∫–ª—é—á–∞–º –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏."""

import json
from datetime import datetime
from pathlib import Path

ROOT = Path(__file__).parent.parent
CATEGORIES_DIR = ROOT / "categories"
OUTPUT_FILE = ROOT / "tasks" / "active" / "META_UPDATE_TZ.md"


def analyze_category(slug_dir: Path) -> dict | None:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Ç–∞ –≥–ª–∞–≤–Ω–æ–º—É –∫–ª—é—á—É."""
    clean_files = list(slug_dir.rglob("*_clean.json"))
    meta_files = list(slug_dir.rglob("*_meta.json"))

    if not clean_files or not meta_files:
        return None

    clean_file = clean_files[0]
    meta_file = meta_files[0]

    try:
        clean_data = json.loads(clean_file.read_text(encoding="utf-8"))
        meta_data = json.loads(meta_file.read_text(encoding="utf-8"))
    except Exception:
        return None

    slug = clean_data.get("id", "")
    name = clean_data.get("name", slug)
    keywords = clean_data.get("keywords", [])

    if not keywords:
        return None

    # –ì–ª–∞–≤–Ω—ã–π –∫–ª—é—á - –ø–µ—Ä–≤—ã–π (—Å –Ω–∞–∏–±–æ–ª—å—à–∏–º volume)
    main_kw = keywords[0]["keyword"]
    main_volume = keywords[0].get("volume", 0)

    # –ú–µ—Ç–∞ –¥–∞–Ω–Ω—ã–µ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞: meta.title, meta.description, h1)
    meta_block = meta_data.get("meta", {})
    title = meta_block.get("title", "") if isinstance(meta_block, dict) else ""
    description = meta_block.get("description", "") if isinstance(meta_block, dict) else ""
    h1 = meta_data.get("h1", "")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –∫–ª—é—á–∞ –≤ –º–µ—Ç–∞
    main_kw_lower = main_kw.lower()
    in_title = main_kw_lower in title.lower()
    in_desc = main_kw_lower in description.lower()
    in_h1 = main_kw_lower in h1.lower()

    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º—ã
    issues = []
    if not in_title:
        issues.append("–≥–ª–∞–≤–Ω—ã–π –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ Title")
    if not in_desc:
        issues.append("–≥–ª–∞–≤–Ω—ã–π –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ Description")
    if not in_h1:
        issues.append("–≥–ª–∞–≤–Ω—ã–π –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ H1")

    return {
        "slug": slug,
        "name": name,
        "main_keyword": main_kw,
        "main_volume": main_volume,
        "keywords_top3": keywords[:3],
        "title": title,
        "description": description,
        "h1": h1,
        "in_title": in_title,
        "in_desc": in_desc,
        "in_h1": in_h1,
        "issues": issues,
        "clean_file": str(clean_file.relative_to(ROOT)),
        "meta_file": str(meta_file.relative_to(ROOT)),
    }


def generate_tz(results: list) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¢–ó."""
    with_issues = [r for r in results if r and r["issues"]]
    ok_results = [r for r in results if r and not r["issues"]]

    lines = [
        "# –¢–ó: –ê–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–∞-—Ç–µ–≥–æ–≤ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–π",
        "",
        f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "**–°—Ç–∞—Ç—É—Å:** ‚¨ú –í —Ä–∞–±–æ—Ç–µ",
        "",
        "---",
        "",
        "## –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
        "",
        "–ü–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ –∫–ª—é—á–µ–π –∏–∑–º–µ–Ω–∏–ª—Å—è –ø–æ—Ä—è–¥–æ–∫ keywords.",
        "–ì–ª–∞–≤–Ω—ã–π –∫–ª—é—á (–ø–µ—Ä–≤—ã–π –ø–æ volume) –¥–æ–ª–∂–µ–Ω –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤:",
        "- **Title** ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ",
        "- **Description** ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ",
        "- **H1** ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞—Ä–∏–∞—Ü–∏—è)",
        "",
        "---",
        "",
        "## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
        "",
        f"- –ö–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: **{len([r for r in results if r])}**",
        f"- –¢—Ä–µ–±—É—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: **{len(with_issues)}**",
        f"- –í –ø–æ—Ä—è–¥–∫–µ: **{len(ok_results)}**",
        "",
        "---",
        "",
    ]

    if with_issues:
        lines.append("## –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        lines.append("")

        for r in sorted(with_issues, key=lambda x: x["main_volume"], reverse=True):
            status_title = "‚úÖ" if r["in_title"] else "‚ùå"
            status_desc = "‚úÖ" if r["in_desc"] else "‚ùå"
            status_h1 = "‚úÖ" if r["in_h1"] else "‚ùå"

            lines.append(f"### ‚¨ú {r['name']} (`{r['slug']}`)")
            lines.append("")
            lines.append(f"**–ì–ª–∞–≤–Ω—ã–π –∫–ª—é—á:** `{r['main_keyword']}` (volume: {r['main_volume']})")
            lines.append("")
            lines.append("**–¢–û–ü-3 –∫–ª—é—á–∞:**")
            for i, kw in enumerate(r["keywords_top3"], 1):
                lines.append(f"{i}. `{kw['keyword']}` ‚Äî {kw.get('volume', 0)}")
            lines.append("")
            lines.append("**–¢–µ–∫—É—â–∏–µ –º–µ—Ç–∞:**")
            lines.append(f"- Title: `{r['title']}`")
            lines.append(
                f"- Description: `{r['description'][:100]}...`"
                if len(r["description"]) > 100
                else f"- Description: `{r['description']}`"
            )
            lines.append(f"- H1: `{r['h1']}`")
            lines.append("")
            lines.append(f"**–°—Ç–∞—Ç—É—Å:** Title {status_title} | Desc {status_desc} | H1 {status_h1}")
            lines.append("")
            lines.append("**–ü—Ä–æ–±–ª–µ–º—ã:**")
            for issue in r["issues"]:
                lines.append(f"- {issue}")
            lines.append("")
            lines.append("**–î–µ–π—Å—Ç–≤–∏—è:**")
            lines.append(f"- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –º–µ—Ç–∞ —Å —É—á—ë—Ç–æ–º –∫–ª—é—á–∞ `{r['main_keyword']}`")
            lines.append(f"- [ ] –§–∞–π–ª: `{r['meta_file']}`")
            lines.append("")
            lines.append("---")
            lines.append("")

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ –ø–æ—Ä—è–¥–∫–µ
    if ok_results:
        lines.append("## –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ –ø–æ—Ä—è–¥–∫–µ (–≥–ª–∞–≤–Ω—ã–π –∫–ª—é—á –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç)")
        lines.append("")
        for r in sorted(ok_results, key=lambda x: x["slug"]):
            lines.append(f"- ‚úÖ {r['name']} (`{r['slug']}`) ‚Äî `{r['main_keyword']}`")
        lines.append("")

    return "\n".join(lines)


def main():
    print("üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ—Ç–∞-—Ç–µ–≥–æ–≤ –≥–ª–∞–≤–Ω—ã–º –∫–ª—é—á–∞–º...\n")

    results = []

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    for item in sorted(CATEGORIES_DIR.iterdir()):
        if item.is_dir():
            result = analyze_category(item)
            if result:
                results.append(result)
                if result["issues"]:
                    print(f"‚ö†Ô∏è  {result['slug']}: {', '.join(result['issues'])}")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¢–ó
    tz_content = generate_tz(results)
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_FILE.write_text(tz_content, encoding="utf-8")

    with_issues = [r for r in results if r and r["issues"]]
    print(f"\n‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len([r for r in results if r])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    print(f"‚ö†Ô∏è  –¢—Ä–µ–±—É—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(with_issues)}")
    print(f"\nüìÑ –¢–ó —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
