# Audit & Optimization Plan — SEO Content Pipeline (Ultimate.net.ua)

**Дата:** 2025-12-12  
**Статус:** Проект изучен полностью, план предложен  
**Контекст:** RU‑only SEO‑контент для категорий интернет‑магазина автохимии

---

## 1. Цель и границы

**Цель проекта:** получить для каждой категории:

```text
Input:  slug + tier (A/B/C)
Output: RU‑текст категории (~1000–2500 chars б/п по tier) + meta (Title/Description)
Quality gate: PASS через scripts/quality_runner.py
```

**В зоне ответственности проекта:**

- подготовка keywords (семантика + volumes + variations);
- генерация контента по `SEO_MASTER.md` (Shop Mode v7.3);
- автоматическая валидация и упаковка deliverables.

**Вне зоны (ручные этапы):**

- Screaming Frog выгрузки конкурентов;
- Perplexity/ручные ТЗ (если нужны).

---

## 2. Текущее состояние (факты)

### 2.1. Ключевые артефакты

- SSOT правил: `SEO_MASTER.md` (v7.3, RU‑only).
- Управление задачами: `task.md` (спринт диагностики keywords).
- Чекпоинты категорий (ожидаемый артефакт): `task_{slug}.json` по `docs/TASK_FILE_SCHEMA.md` — **в текущем workspace отсутствуют**, должны создаваться `scripts/setup_all.py`.
- Рабочие папки категорий (ожидаемый артефакт): `categories/{slug}/...` — **в текущем workspace отсутствуют**, должны создаваться `scripts/setup_all.py`.
- Входные данные:
  - `data/Структура  Ultimate финал - Лист2.csv` — L1/L2/L3 семантика + volumes.
  - `data/поисковая_выдача_топ_10.csv` — SERP URLs.
  - `data/mega/mega_competitors.csv` — SF выгрузка конкурентов.

### 2.2. Скрипты пайплайна

Основные:

- `scripts/parse_semantics_to_json.py`
- `scripts/setup_all.py`
- `scripts/check_simple_v2_md.py`
- `scripts/check_water_natasha.py`
- `scripts/check_ner_brands.py`
- `scripts/quality_runner.py`

Вспомогательные/устаревшие: `quality_check_stage_8_1.sh`, `parse_hubs_logic.py`, `mega_url_extract.py`, др. (см. `scripts/README.md`).

### 2.3. Статус категорий

Целевых slug — 9 (см. `INDEX.md`).  
Готова только `aktivnaya-pena` (PASS).

### 2.4. Статус тестов и покрытия

- Тесты запускаются из venv: `venv/bin/python -m pytest`.
- Текущее состояние: **367 passed, 0 failed**.
- Coverage (pytest-cov): **81%**; основные “скрипты с нулём” переведены на in-process тестирование и покрыты юнит/CLI-тестами.

### 2.5. Файловый инвентарь (актуальный workspace)

**Есть в корне:**

- Документация/управление: `README.md`, `INDEX.md`, `CLAUDE.md`, `SEO_MASTER.md`, `task.md`, `ORCHESTRATOR_PROMPT.md`, `WORKER_PROMPT.md`, `AUDIT_AND_OPTIMIZATION_PLAN.md`.
- Код: `scripts/`, `tests/`, `verify_refactoring.py`.
- Конфиги: `.pre-commit-config.yaml`, `pyproject.toml`, `pytest.ini`, `requirements.txt`, `requirements_minimal.txt`, `.markdownlint.json`, `.gitignore`.
- Данные: `data/` (и дубли CSV/XLSX в корне).
- Архивы: `archive/` и `docs/archive/` (две разные “архивные” зоны).

**Есть, но по смыслу не используется/пусто:**

- `content/` (в текущем состоянии почти пуст).

**Отсутствует, но ожидается по докам/скриптам:**

- `categories/` (workspace категорий).
- `task_{slug}.json` (state-файлы категорий).

---

## 3. Главные проблемы (подтверждено по коду/данным)

### 3.1. **Сломанные keywords.json**

**Симптом:** `keywords.json` большинства категорий нерелевантны (ключи “перемешаны”).  
**Подтверждение:** в `categories/dlya-ruchnoy-moyki/data/dlya-ruchnoy-moyki.json` primary‑ключи про омыватели/антидождь.

**Корень:** `read_semantics_csv()` в `scripts/parse_semantics_to_json.py` сбрасывает категорию только на строках `L1:`/`L2:`/`L3:`.  
В реальном CSV есть **границы без префиксов**, напр. строка `категория,16,` после блока L3. Парсер не сбрасывает `current_l3`, и следующие ключи попадают в предыдущую L3.

**Следствие:** контент‑валидаторы и генерация работают на неверной семантике → тексты будут нерелевантны.

### 3.2. **Дрейф архитектуры/документации**

Сейчас живут одновременно:

1. Root‑доки (v5–6): skills/sub‑agents, 3 этапа `PREPARE/PRODUCE/DELIVER`, RU‑only.
2. `docs/archive/*` (v10): стадийный workflow с MANUAL STAGE 3 и UA‑переводом.
3. `VISION.md`: предлагает минимальный pipeline без skills/prompts/старых docs.

**Проблема:** непонятно, что канон → выше когнитивная нагрузка, риск работать “не по той версии”.

### 3.3. **Тесты не моделируют реальный CSV**

`tests/test_parse_semantics_to_json.py` использует идеальный CSV без непомеченных подзаголовков/границ.  
**Баг парсера не ловится тестами.**

### 3.4. Редундантность файлов/скриптов

- Дубли входных CSV в `data/` и `data/input/`.
- Наборы skills и prompts дублируют `SEO_MASTER.md`/root‑workflow.
- Устаревшие workflow‑доки живут рядом с активными.

### 3.5. **Неверные пороги в quality_runner.py**

В `scripts/quality_runner.py`:

- Classic Nausea считается PASS при `<=7`, тогда как SSOT v7.3 требует `<=3.5` (blocker >4.0).
- Water фиксирован на 40–60% для всех tiers, хотя Tier C допускает 40–65%.
- Пороги не берутся из `scripts/seo_utils.get_tier_requirements()`.
    **Следствие:** статус PASS/WARN сейчас ненадёжен.

### 3.6. **Скрипты URL/конкурентов не согласованы с текущей структурой**

- `scripts/extract_competitor_urls_v2.py` читает CSV по неверному пути (не из `data/…`) и пишет в legacy‑структуру `content/categories/...`.
- `scripts/url_preparation_filter_and_validate.py` ожидает `task_{slug}.json` с путями `urls_raw/urls/logs`, которых нет в task‑файлах, создаваемых `scripts/setup_all.py`.
- В skill‑описаниях `seo-urls` указаны CLI‑флаги, которых нет в реальных скриптах.
    **Следствие:** этапы URL Extraction/Preparation сейчас нельзя безопасно запускать без правок.

### 3.7. **Дрейф task schema ↔ skills ↔ prompts**

- Каноническая схема task описана в `docs/TASK_FILE_SCHEMA.md` и реализована в `scripts/setup_all.py`.
- Skills и sub‑agent prompts описывают другие стадии/поля и местами противоречат правилам (например, `prompts/deliver.md` запрещает H1).
    **Следствие:** sub‑agents/skills могут создавать неправильные файлы и ломать recovery.

### 3.8. **Документация и ссылки не соответствуют текущим файлам**

- `README.md` и `INDEX.md` ссылаются на `categories/README.md`, но директории `categories/` сейчас нет.
- `docs/README.md` называет “активными” документы, которых нет в `docs/` (они лежат в `docs/archive/`), и ссылается на файлы в корне, которых нет.
- `tests/README.md` содержит устаревшие цифры (кол-во тестов/coverage/зависимости).
- `run_tests.bat` запускает `tests/unit/`, которой нет.

### 3.8. **Legacy и дубли увеличивают шум**

- В корне лежит устаревший дубль `check_water_natasha.py` (не использовать).
- Bash‑утилиты (`validate_category.sh`, `check_lsi_metrics.sh`, `fix_paths_unified_structure.sh`, `update_agent_paths.sh`) ориентированы на старые структуры/пороговые версии.
- Скрипты `mega_url_extract.py` и `parse_hubs_logic.py` относятся к legacy‑workflow и не используются в текущей задаче 9 категорий.

### 3.9. **Слабая деградация fallback‑режимов**

- При отсутствии `data/mega/mega_urls_map.csv` `filter_mega_competitors.py` фильтрует конкурентов только по 5 ключам → для больших кластеров может давать 0 конкурентов.

### 3.10. **Неповторяемая среда разработки**

- `requirements.txt` не фиксирует dev‑зависимости (`pytest`, `pytest-cov`, `ruff`, `mypy`, `bandit`, `pre-commit`), хотя:
  - `pytest.ini` включает `--cov` и плагины,
  - `pyproject.toml` и `.pre-commit-config.yaml` на них опираются.
        **Следствие:** окружение невозможно восстановить одной командой `pip install -r requirements.txt`.

### 3.11. **Дубли входных данных**

В проекте одновременно присутствуют:

- `data/input/…` и `data/…` (дубли одинаковых CSV),
- дубли CSV в корне (`поисковая_выдача_топ_10.csv`, `list_mode_export.csv`, “Структура … Лист1/Лист2 …”).
    **Следствие:** непонятно, какой файл SSOT; скрипты читают разные пути.

---

## 4. Цели оптимизации

1. **Вернуть корректную семантику** как SSOT для генерации.
2. **Снять архитектурный дрейф:** один канонический workflow, остальное — архив.
3. **Упростить репо:** оставить только реально используемые скрипты/доки.
4. **Поднять надёжность:** тесты на реальные данные, повторяемый rebuild.
5. **Сократить время на категорию:** <30 минут до PASS.

---

## 5. Предлагаемая каноническая архитектура (выбор)

### Вариант 1 — Сохранить текущий root‑workflow (skills/sub‑agents)

**Канон:** `README.md`, `CLAUDE.md`, `SEO_MASTER.md`, `task.md`.  
**Что делаем:** чистим мусор, исправляем парсер, генерим контент через стадии 0–8.

**Плюсы:** ничего не ломаем, меньше миграций.  
**Минусы:** остаётся “слой” skills/prompts, который не всем нужен.

### Вариант 2 — Минимальный pipeline по `VISION.md`

**Канон:** `SEO_MASTER.md` + структура `categories/{slug}/(keywords.json, content_ru.md, meta.json)` + `quality_runner.py`.  
Skills/prompts/старые docs уходят в архив.

**Плюсы:** минимальная когнитивная модель, быстрее руками.  
**Минусы:** теряем автоматизацию stages и экономию токенов sub‑agents.

**Нужен ваш выбор**, чтобы зафиксировать SSOT.

---

## 6. План оптимизации (по фазам)

### Фаза 0 — Зафиксировать канон (30 мин)

- [ ] Выбрать архитектуру: Вариант 1 или 2 (см. раздел 5).
- [ ] Зафиксировать активные документы (список SSOT).
- [ ] Всё неканоническое переместить в `archive/` (одну общую зону) + обновить `INDEX.md` и удалить/исправить битые ссылки.

**Результат:** один понятный workflow без конфликтов.

### Фаза 0.5 — Восстановить рабочую зону (10 мин)

Так как в текущем workspace нет `categories/` и `task_{slug}.json`:

- [ ] Запуск `python3 scripts/setup_all.py` (или `--dry-run` → затем `--force` при необходимости).
- [ ] Проверка: появились `categories/{slug}/...` и `task_{slug}.json`.

### Фаза 1 — Починка keywords (2–4 часа)

Нужно выбрать источник:

### A) Ручная правка JSON (быстро)

- [ ] Открыть 9 файлов `categories/{slug}/data/{slug}.json`.
- [ ] Удалить нерелевантные ключи, оставить свои.
- [ ] Сверить по CSV/интуитивной релевантности.  
         **Риск:** ручные ошибки, нет повторяемости.

### B) Исправить парсер + тесты (правильно)

- [ ] Исправить `read_semantics_csv()` для реального CSV:
  - распознавать непомеченные подзаголовки/границы;
  - корректно завершать L3‑блоки;
  - аккуратно работать с `2/5`, `3/59`, пустыми строками.
- [ ] Добавить тесты на:
  - строку‑границу без `L2/L3` (напр. `категория,16,`);
  - подзаголовки вида `Омыватель,35,`;
  - счётчики `2/5` и `N/M`.
- [ ] Перегенерировать все JSON (`setup_all.py --force` или `parse_semantics_to_json.py` по slug).
        **Плюс:** повторяемо, защищено тестами.

### C) Новый “чистый” CSV (идеально)

- [ ] Собрать новый CSV: `slug,keyword,volume,intent`.
- [ ] Упростить парсер под новую схему.
- [ ] Перегенерировать JSON.
        **Плюс:** навсегда убирает L1/L2/L3 хаос.  
         **Минус:** больше времени на подготовку данных.

**Результат:** 9 корректных keywords JSON.

### Фаза 2 — Cleanup репозитория (1–2 часа)

- [ ] Убрать дубли:
  - `data/input/` оставить только если реально используется; иначе архивировать.
  - `docs/archive/` явно пометить как архив (и исключить из “активных” списков).
- [ ] Архивировать/удалить всё неиспользуемое по выбранному канону:
  - лишние skills/prompts (если Вариант 2);
  - устаревшие bash‑скрипты, которые задепрекейчены `quality_runner.py`;
  - “исторические” docs/plan‑файлы.

**Результат:** репо <30 активных файлов.

### Фаза 2.5 — Актуализация документации и команд (30–60 мин)

- [ ] Исправить/удалить битые ссылки на `categories/README.md`.
- [ ] Обновить `docs/README.md` (или перенести в архив), чтобы он не ссылался на несуществующие файлы.
- [ ] Обновить `tests/README.md` под реальную конфигурацию `pytest.ini` и текущие результаты.
- [ ] Исправить `run_tests.bat` под фактические пути (`tests/`), либо удалить как legacy.

### Фаза 3 — Test Run (1 категория) (30–60 мин)

- [ ] Выбрать категорию с корректными keywords.
- [ ] Сгенерировать контент RU по `SEO_MASTER.md`.
- [ ] Прогнать `scripts/quality_runner.py` до PASS.
- [ ] Замерить время/токены/типовые ошибки → записать в `task.md`.

**Результат:** эталонный “проход” pipeline.

### Фаза 4 — Production на 8 категорий (4–6 часов)

- [ ] Повторить генерацию + валидацию для остальных 8 slug.
- [ ] В каждой категории заполнить `deliverables/`.

**Результат:** полный комплект текстов и meta.

### Фаза 5 — Укрепление качества (по желанию)

- [ ] Довести coverage до 50–60%:
  - тесты для `quality_runner.py`;
  - расширить тесты `check_water_natasha.py` на edge‑кейсы.
- [ ] Зафиксировать команды “one‑liner” для всего цикла в README.

---

## 7. Риски и как их снижать

- **Ручная правка keywords (A) уедет в ошибки.**  
     Митигация: хотя бы частично автоматизировать через B, или добавить чек‑лист релевантности.
- **Дрейф спецификаций (v7.3 vs старые v10).**  
     Митигация: SSOT‑лист + архив старого.
- **Сломать пайплайн cleanup‑ом.**  
     Митигация: сначала Фаза 0 (канон), потом архивирование.

---

## 8. Definition of Done

Проект считается готовым, когда:

- Для каждого из 9 slug:
  - `categories/{slug}/data/{slug}.json` релевантен и подтверждён;
  - `categories/{slug}/content/{slug}_ru.md` PASS в `quality_runner.py`;
  - `categories/{slug}/meta/{slug}_meta.json` валиден по длинам;
  - `categories/{slug}/deliverables/` содержит финальные файлы.
- Root‑доки не противоречат друг другу и отражают канон.
- Парсер семантики покрыт тестами на реальный формат CSV.

---

### Приложение: Статус компонентов (по глубокому аудиту)

- `parse_semantics_to_json.py` — ключевой, требует фикса CSV‑границ и тестов под реальный файл.
- `quality_runner.py` — пороги water/nausea не соответствуют v7.3; нужен tier‑aware рефакторинг.
- `extract_competitor_urls_v2.py` + `url_preparation_filter_and_validate.py` — требуют выравнивания путей/CLI и структуры категорий.
- `check_simple_v2_md.py`, `check_water_natasha.py`, `check_ner_brands.py`, `seo_utils.py`, `setup_all.py` — в целом рабочие и соответствуют SSOT после починки входной семантики.
- Остальные скрипты — legacy/диагностика; судьба зависит от выбранного канона (обновить или архивировать).

### Приложение: Что удалить/архивировать (после выбора канона)

**Почти наверняка в архив/удаление:**

- `scripts/update_agent_paths.sh`, `scripts/fix_paths_unified_structure.sh` (ссылаются на несуществующую `.claude/agents`).
- `scripts/validate_category.sh` (ожидает файлы/стадии, которых нет в текущем pipeline).
- `scripts/check_lsi_metrics.sh` (legacy-метрики и старые targets).
- `scripts/quality_check_stage_8_1.sh` (уже deprecated).
- `scripts/tests/` (либо перенести в `tests/` и включить в pytest, либо удалить как legacy-unittest).
- `scripts/__pycache__/`, `tests/__pycache__/`, `.coverage`, `coverage.json`, `htmlcov/` (генерируемое; должно быть вне репо).

**Дубли данных (выбрать SSOT и убрать остальное):**

- `data/input/Структура  Ultimate финал - Лист2.csv` vs `data/Структура  Ultimate финал - Лист2.csv` vs root-версии.
- `data/input/поисковая_выдача_топ_10.csv` vs `data/поисковая_выдача_топ_10.csv` vs root-версия.
- `data/list_mode_export.csv` vs `list_mode_export.csv`.
- `docs/archive/` vs `archive/` (двойной архив).

## 9. Следующее действие

1. Выберите архитектуру (раздел 5).
2. Выберите путь восстановления keywords (A/B/C).  
   После этого я могу:

- сделать патч парсера + тесты (если B);
- или помочь с ручной правкой JSON (если A);
- или подготовить новую CSV‑схему и скрипт (если C).
