#!/usr/bin/env python3
"""
restore_from_csv.py ‚Äî –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç _clean.json –∏–∑ CSV —Å–µ–º–∞–Ω—Ç–∏–∫–∏

–î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π, —É –∫–æ—Ç–æ—Ä—ã—Ö —É–¥–∞–ª–∏–ª–∏—Å—å –∫–ª—é—á–∏ –ø–æ—Å–ª–µ auto-fix.
"""

import csv
import json
from pathlib import Path


SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
SEMANTICS_CSV = PROJECT_ROOT / "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ _Ultimate.csv"
CATEGORIES_DIR = PROJECT_ROOT / "categories"

# Mapping slug ‚Üí CSV block name
SLUG_TO_CSV = {
    "mikrofibra-i-tryapki": "–ú–∏–∫—Ä–æ—Ñ–∏–±—Ä–∞ –∏ —Ç—Ä—è–ø–∫–∏",
    "shchetki-i-kisti": "–©–µ—Ç–∫–∏ –∏ –∫–∏—Å—Ç–∏",
    "mekhovye": "–ú–µ—Ö–æ–≤—ã–µ",
    "s-voskom": "–° –≤–æ—Å–∫–æ–º",
}

# Sub-block mappings (keywords under special sub-headers in "–ù–∞–±–æ—Ä—ã" section)
SLUG_TO_SUBBLOCKS = {
    "nabory-dlya-moyki": ["–Ω–∞–±–æ—Ä –¥–ª—è –º–æ–π–∫–∏ –∞–≤—Ç–æ", "–Ω–∞–±–æ—Ä —Ç—Ä—è–ø–æ–∫ –¥–ª—è –º–∞—à–∏–Ω—ã"],
    "nabory-dlya-polirovki": ["–Ω–∞–±–æ—Ä –∫—Ä—É–≥–æ–≤ –¥–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ", "–Ω–∞–±–æ—Ä –ø–∞—Å—Ç –¥–ª—è –ø–æ–ª–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ"],
    "nabory-dlya-khimchistki": ["–Ω–∞–±–æ—Ä –¥–ª—è —Ö–∏–º—á–∏—Å—Ç–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è", "–Ω–∞–±–æ—Ä –¥–ª—è —á–∏—Å—Ç–∫–∏ —Å–∞–ª–æ–Ω–∞ –∞–≤—Ç–æ"],
    "nabory-dlya-kozhi": ["–Ω–∞–±–æ—Ä –¥–ª—è —É—Ö–æ–¥–∞ –∑–∞ –∫–æ–∂–µ–π –∞–≤—Ç–æ"],
    "nabory-dlya-deteylinga": ["–Ω–∞–±–æ—Ä—ã –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞", "–Ω–∞–±–æ—Ä –∫–∏—Å—Ç–µ–π –¥–ª—è –¥–µ—Ç–µ–π–ª–∏–Ω–≥–∞"],
    "podarochnye-nabory": ["–ø–æ–¥–∞—Ä–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –∞–≤—Ç–æ", "–ø–æ–¥–∞—Ä–æ—á–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –¥–ª—è –º—É–∂—á–∏–Ω –≤ –º–∞—à–∏–Ω—É"],
}

# Commercial modifiers
COMMERCIAL_MODIFIERS = ["–∫—É–ø–∏—Ç—å", "—Ü–µ–Ω–∞", "–∑–∞–∫–∞–∑–∞—Ç—å", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–Ω–µ–¥–æ—Ä–æ–≥–æ", "–æ–ø—Ç–æ–º"]


def parse_csv_block(block_name: str) -> list[dict]:
    """Parse all keywords from a CSV block."""
    keywords = []
    current_block = None

    with open(SEMANTICS_CSV, encoding="utf-8") as f:
        reader = csv.reader(f)
        for row in reader:
            if not row or not row[0].strip():
                continue

            phrase = row[0].strip()
            volume_str = row[2].strip() if len(row) > 2 else ""

            # Detect block headers
            for prefix in ["L1:", "L2:", "L3:", "SEO-–§–∏–ª—å—Ç—Ä:"]:
                if phrase.startswith(prefix):
                    name = phrase.replace(prefix, "").strip()
                    if name == block_name:
                        current_block = name
                    elif current_block:
                        # Exit block
                        return keywords
                    break
            else:
                # Not a header - check if keyword
                if current_block and volume_str.isdigit():
                    keywords.append({"keyword": phrase, "volume": int(volume_str)})

    return keywords


def parse_csv_subblocks(subblock_names: list[str]) -> list[dict]:
    """Parse keywords from multiple sub-blocks in the '–ù–∞–±–æ—Ä—ã' section."""
    keywords = []
    current_subblock = None
    in_nabory = False

    with open(SEMANTICS_CSV, encoding="utf-8") as f:
        reader = csv.reader(f)
        for row in reader:
            if not row or not row[0].strip():
                continue

            phrase = row[0].strip()
            count_str = row[1].strip() if len(row) > 1 else ""
            volume_str = row[2].strip() if len(row) > 2 else ""

            # Check for "–ù–∞–±–æ—Ä—ã" parent block
            if phrase == "–ù–∞–±–æ—Ä—ã" and count_str:
                in_nabory = True
                continue

            # Exit –ù–∞–±–æ—Ä—ã section on next L1/L2/L3 header
            if in_nabory and phrase.startswith(("L1:", "L2:", "L3:")):
                break

            if not in_nabory:
                continue

            # Check for sub-block header (has count like "2/10" or "2")
            if count_str and ("/" in count_str or count_str.isdigit()) and not volume_str:
                # This is a sub-block header
                if phrase.lower() in [n.lower() for n in subblock_names]:
                    current_subblock = phrase
                else:
                    current_subblock = None
                continue

            # Parse keyword
            if current_subblock and volume_str.isdigit():
                keywords.append({"keyword": phrase, "volume": int(volume_str)})

    return keywords


def cluster_keywords(keywords: list[dict]) -> dict:
    """Cluster keywords into primary/secondary/supporting/commercial."""
    # Sort by volume descending
    sorted_kws = sorted(keywords, key=lambda x: x["volume"], reverse=True)

    primary = []
    secondary = []
    supporting = []
    commercial = []

    for kw in sorted_kws:
        keyword = kw["keyword"]
        volume = kw["volume"]

        # Skip zero volume
        if volume == 0:
            continue

        # Check if commercial
        is_commercial = any(mod in keyword.lower() for mod in COMMERCIAL_MODIFIERS)

        if is_commercial:
            commercial.append(
                {
                    "keyword": keyword,
                    "volume": volume,
                    "cluster": "commercial",
                    "use_in": "meta_only",
                }
            )
        elif volume >= 300:
            primary.append({"keyword": keyword, "volume": volume, "cluster": "main"})
        elif volume >= 50:
            secondary.append({"keyword": keyword, "volume": volume, "cluster": "related"})
        else:
            supporting.append({"keyword": keyword, "volume": volume, "cluster": "long_tail"})

    return {
        "primary": primary[:5],  # Top 5
        "secondary": secondary[:10],  # Top 10
        "supporting": supporting[:15],  # Top 15
        "commercial": commercial[:5],  # Top 5
    }


def restore_category(slug: str) -> bool:
    """Restore a category's _clean.json from CSV."""
    csv_name = SLUG_TO_CSV.get(slug)
    subblocks = SLUG_TO_SUBBLOCKS.get(slug)

    if not csv_name and not subblocks:
        print(f"  ‚ùå No CSV mapping for {slug}")
        return False

    # Parse CSV (either from main block or subblocks)
    if csv_name:
        keywords = parse_csv_block(csv_name)
        source = f"CSV block '{csv_name}'"
    else:
        keywords = parse_csv_subblocks(subblocks)
        source = f"sub-blocks {subblocks}"

    if not keywords:
        print(f"  ‚ùå No keywords in {source}")
        return False

    # Cluster
    clustered = cluster_keywords(keywords)

    # Read existing file
    clean_path = CATEGORIES_DIR / slug / "data" / f"{slug}_clean.json"
    if clean_path.exists():
        with open(clean_path, encoding="utf-8") as f:
            data = json.load(f)
    else:
        data = {"slug": slug, "language": "ru"}

    # Update keywords
    data["keywords"] = clustered

    # Update stats
    total_kws = sum(
        len(clustered[cat]) for cat in ["primary", "secondary", "supporting", "commercial"]
    )
    total_vol = sum(kw["volume"] for cat in clustered.values() for kw in cat)
    data["stats"] = {"before": len(keywords), "after": total_kws, "total_volume": total_vol}

    # Add note
    data["restored_from"] = f"{source} ({len(keywords)} raw keywords)"

    # Write
    with open(clean_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"  ‚úÖ {slug}: {total_kws} keywords from {len(keywords)} raw")
    return True


def main():
    print("üîÑ Restoring categories from CSV...\n")

    # Categories from main blocks
    main_block_cats = ["mikrofibra-i-tryapki", "shchetki-i-kisti", "mekhovye", "s-voskom"]

    # Categories from sub-blocks
    subblock_cats = [
        "nabory-dlya-moyki",
        "nabory-dlya-polirovki",
        "nabory-dlya-khimchistki",
        "nabory-dlya-kozhi",
        "nabory-dlya-deteylinga",
        "podarochnye-nabory",
    ]

    categories = main_block_cats + subblock_cats

    restored = 0
    for slug in categories:
        if restore_category(slug):
            restored += 1

    print(f"\n‚úÖ Restored {restored}/{len(categories)} categories")


if __name__ == "__main__":
    main()
